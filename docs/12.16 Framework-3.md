**“软性探测 (Soft Probing)”** 确实只能作为一种辅助手段（Bonus），不能作为系统闭环的依赖点。因为用户的显式反馈是稀疏且不可控的，过分依赖会使系统变得脆弱。

我们的核心逻辑必须建立在 **“隐式验证 (Implicit Verification)”** 之上：即 Agent 生成假设后，通过观察用户**后续的自然行为**（是否与假设一致）来验证假设，而不是非要问用户一句。

# Proactive Cognitive Memory (PCM): A Surprise-Driven Self-Evolving Framework

## 1. 核心设计哲学 (Core Design Philosophy)

PCM 系统旨在构建一个具备 **"主动感知 (Proactive Perception)"** 和 **"自主演化 (Autonomous Evolution)"** 能力的智能体记忆系统。

*   **Beyond Storage:** 记忆不仅是存储库，更是**预测机 (Prediction Machine)**。
*   **Surprise as Driver:** 系统的演化不依赖人工规则，而是由 **惊奇度 (Surprisal)** ——即“预期与现实的偏差”——所驱动。
*   **Hypothesis over Summary:** 系统对新信息的处理不只是压缩（Summary），更是生成关于用户意图的**假设 (Hypothesis)**。

---

## 2. 整体架构概览 (Architecture Overview)

系统由三个层级组成，形成 **"感知 (L1) -> 预测与存储 (L2) -> 演化与推理 (L3)"** 的闭环。

### Layer 1: Perception & Working Memory (感知与工作记忆层)
*   **功能：** 实时交互的前台，负责短期记忆维护、意图路由和惊奇度监测。
*   **组件：** `SlidingContextQueue`, `IntentRouter`, `SurpriseMonitor`.

### Layer 2: Probabilistic World Model (概率世界模型层)
*   **功能：** 结构化的后台，存储加权知识图谱，支持柔性更新。
*   **组件：** `WeightedKnowledgeGraph` (Nodes, Edges, Weights).

### Layer 3: Cognitive Evolution Engine (认知演化引擎)
*   **功能：** 异步的中台，基于惊奇度分级策略，对 L2 进行修正、假设生成和维护。
*   **组件：** `SurpriseDispatcher`, `CorrectionAgent`, `ProfilingAgent`, `MaintenanceAgent`.

---

## 3. 详细模块设计 (Detailed Module Design)

### 3.1 Layer 1: Perception & Working Memory

#### A. Sliding Context Queue (滑动上下文队列)
*   **机制：** 维护一个固定 Token 窗口（如 2k tokens）的对话历史。
*   **Eviction (驱逐):** 当队列满时，最早的 $k$ 轮对话被移出。
*   **Output:** 被移出的数据包 $D_{evicted}$ 不会被丢弃，而是作为 **Raw Material** 发送给 Layer 3。

#### B. Intent Router (意图路由器)
*   **输入：** 当前用户 Query $u_t$。
*   **动作：** 快速分析 $u_t$ 的领域（Coding, Academic, Personal...）。
*   **输出：** 生成 **Intent Mask $M_{intent}$**。
*   **作用：** 指导 L2 仅检索与当前意图相关的子图，屏蔽噪声。

#### C. Surprise Monitor (惊奇监测器) —— *The Gatekeeper*
*   **输入：** 用户 Query $u_t$ + L2 检索结果 $C_{retrieved}$。
*   **计算：** 计算 **Surprisal Score $S$** (基于 LLM 的 NLL 或 Perplexity)。
    $$ S(u_t) = - \log P(u_t | C_{retrieved}) $$
*   **输出：** 将 $S$ 附加到 $D_{evicted}$ 上，传递给 Layer 3。

---

### 3.2 Layer 2: Probabilistic World Model

#### A. Weighted Knowledge Graph (加权知识图谱)
图谱 $G = (V, E)$ 是系统的核心存储。
*   **Nodes:** 实体 (Entities)、属性 (Attributes)、**假设 (Hypotheses)**。
*   **Edges:** 关系 $e = (u, v, r, w)$。
    *   **$w$ (Confidence Weight):** $0 \le w \le 1$。表示该知识点的可靠程度。
    *   **Soft Update:** 冲突时不删除，而是降低 $w$；验证时提高 $w$。

#### B. Intent-Masked Retrieval (意图掩码检索)
*   **机制：**
    1.  接收 L1 的 $M_{intent}$。
    2.  激活 L2 中对应领域的子图。
    3.  在子图中进行 **加权随机游走 (Weighted Random Walk)** 或 **向量检索**。
*   **结果：** 返回高置信度、高相关性的 Context。

---

### 3.3 Layer 3: Cognitive Evolution Engine —— *The Brain*

这是系统的核心创新点。L3 接收 L1 溢出的数据包 $(D_{evicted}, S)$，并根据 $S$ 的值进行分级处理。

#### A. Surprise Dispatcher (惊奇分发器)
根据 $S$ 值将任务分发给不同的 Sub-Agent：

1.  **High Surprise ($S > \theta_{high}$):** -> **Correction Agent**
2.  **Medium Surprise ($\theta_{low} < S \le \theta_{high}$):** -> **Profiling Agent**
3.  **Low Surprise ($S \le \theta_{low}$):** -> **Maintenance Agent**

#### B. Branch 1: Correction Agent (修正代理) —— *High Surprise*
*   **场景：** 剧烈冲突（如用户推翻了之前的偏好）。
*   **动作 (Deep Reasoning):**
    1.  **Diagnose:** 分析冲突原因（用户变了？L2 记错了？）。
    2.  **Decay:** 大幅降低 L2 中旧知识节点的权重 $w_{old} \leftarrow w_{old} \cdot \alpha$。
    3.  **Overwrite:** 创建新节点，赋予高初始权重。
*   **价值：** 快速纠错，防止幻觉持续。

#### C. Branch 2: Profiling Agent (侧写代理) —— *Medium Surprise (Core Innovation)*
*   **场景：** 新颖信息或潜在模式（无直接冲突，但意料之外）。
*   **动作 (Hypothesis Generation):**
    1.  **Internal Monologue:** *"用户提到了高性能计算，这与之前的 Web 开发画像不同，但并不冲突。这是否意味着他在做一个新项目？"*
    2.  **Create Hypothesis:** 在 L2 中创建一个 **"Hypothesis Node"** (e.g., `Hypothesis: User is working on HPC Project`).
    3.  **Implicit Verification (隐式验证):**
        *   该节点初始权重较低（如 $w=0.3$）。
        *   **关键机制：** 如果未来的 $D_{evicted}$ 中再次出现相关证据，Maintenance Agent 会自动提升这个 $w$。如果长期未出现，该节点会因权重过低被 Prune（剪枝）。
*   **价值：** **主动感知**。系统在没有用户指令的情况下，自主构建关于未来的假设，并通过后续事实自动验证。

#### D. Branch 3: Maintenance Agent (维护代理) —— *Low Surprise*
*   **场景：** 符合预期（重复性信息）。
*   **动作 (Reinforcement):**
    1.  **Boost:** 提升 L2 中相关节点的权重 $w \leftarrow \min(1.0, w + \beta)$。
    2.  **Update Timestamp:** 刷新最后访问时间，防止被遗忘算法清除。
*   **价值：** 巩固记忆，形成长期的“肌肉记忆”。

---

## 4. 系统工作流示例 (Workflow Walkthrough)

**场景：用户从 Python Web 开发转向 AI 研究。**

1.  **Phase 1 (Low Surprise):** 用户问 "Django 怎么配置？"
    *   L1: 检索到 Python Web 知识。
    *   L3 (Maintenance): 强化 `User_Skill: Django` 的权重。

2.  **Phase 2 (Medium Surprise):** 用户突然问 "PyTorch 的 Tensor 怎么优化？"
    *   L1: 检索到 Python，但没检索到 PyTorch。$S$ 值中等（是 Python，但领域不同）。
    *   L3 (Profiling):
        *   思考：*"用户开始问 AI 框架了，可能在转型？"*
        *   操作：在 L2 创建假设节点 `Hypothesis: Interest in AI`，权重 $0.4$。

3.  **Phase 3 (Implicit Verification):** 用户接着问 "Transformer 的 Attention 机制？"
    *   L1: 检索到 `Hypothesis: Interest in AI`。
    *   L3 (Maintenance): 发现新证据支持该假设！
        *   操作：将 `Hypothesis: Interest in AI` 升级为 **Fact Node** `User_Interest: AI`，权重提升至 $0.8$。

4.  **Phase 4 (High Surprise):** 用户说 "以后别给我推 Web 的库了，我只做 AI。"
    *   L1: 检索到 `User_Interest: Web`。$S$ 值极高（直接冲突）。
    *   L3 (Correction):
        *   操作：将 `User_Interest: Web` 的权重降至 $0.1$（保留但不激活），确保未来回答聚焦 AI。
