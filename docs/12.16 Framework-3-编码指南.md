# Proactive Cognitive Memory (PCM) Implementation Blueprint

## 1. 项目背景 (Project Context)
本项目旨在实现一个名为 **PCM** 的智能体记忆系统。该系统超越了传统的 RAG（检索增强生成），具备 **主动感知 (Proactive Perception)** 和 **自主演化 (Autonomous Evolution)** 能力。
核心逻辑基于 **双重加工理论** 和 **自由能原理**：
1.  **Layer 1 (Perception):** 处理实时交互，计算“惊奇度 (Surprisal)”，维护滑动窗口。
2.  **Layer 2 (World Model):** 维护一个 **加权知识图谱 (Weighted Knowledge Graph)**，支持基于意图的掩码检索和柔性权重更新。
3.  **Layer 3 (Cognitive Engine):** 异步处理，根据惊奇度高低，分别执行 **修正 (Correction)**、**假设生成 (Profiling)** 或 **权重维护 (Maintenance)**。

---

## 2. 技术栈与依赖 (Tech Stack & Dependencies)

请在 `requirements.txt` 中包含以下核心库：

*   **Core Logic:** `python >= 3.10`, `numpy`, `scikit-learn` (用于计算熵和聚类)
*   **LLM Interface:** `openai` (标准 API 调用), `pydantic` (结构化输出与数据验证)
*   **Graph Database:** `networkx` (用于构建内存中的知识图谱，适合科研原型)
*   **Vector Database:** `chromadb` (轻量级向量数据库，支持元数据过滤)
*   **Embeddings & Local Models:**
    *   `sentence-transformers` (用于文本嵌入)
    *   `torch` (PyTorch backend)
    *   `transformers` (Hugging Face 库，用于加载本地模型计算 Perplexity)
*   **Environment:** `python-dotenv`

---

## 3. 模型选择 (Model Specifications)

请在代码配置中明确使用以下模型：

1.  **Main Agent LLM (推理与生成):**
    *   API: OpenAI Compatible
    *   Model: `gpt-4o` (推荐) 或 `gpt-4o-mini` (调试用)。
2.  **Embedding Model (向量化):**
    *   Source: Hugging Face
    *   Model ID: `sentence-transformers/all-MiniLM-L6-v2`
    *   *理由：速度快，维度适中 (384 dim)，适合科研快速迭代。*
3.  **Surprisal Scoring Model (惊奇度计算):**
    *   Source: Hugging Face (Local)
    *   Model ID: `gpt2` (Small) 或 `TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T`
    *   *理由：我们需要一个本地 Causal LM 来计算 Token 的 Negative Log-Likelihood (NLL)，调用 API 计算 Logprobs 成本过高且延迟大。*

---

## 4. 项目目录结构 (Directory Structure)

```text
pcm-system/
├── .env                    # API Keys (OPENAI_API_KEY)
├── requirements.txt
├── main.py                 # 系统入口与交互 Demo
├── config.py               # 全局配置 (阈值 theta_low, theta_high, 模型路径)
├── data/                   # 持久化存储 (ChromaDB, Graph JSON)
└── src/
    ├── __init__.py
    ├── core/               # 核心编排
    │   ├── orchestrator.py # PCMSystem 类，连接 L1, L2, L3
    │   └── types.py        # Pydantic 数据模型 (MemoryNode, Edge, Intent)
    ├── layers/             # 三层架构实现
    │   ├── layer1_perception.py  # SlidingQueue, IntentRouter, SurpriseMonitor
    │   ├── layer2_world_model.py # KnowledgeGraph, VectorStore, Retrieval
    │   └── layer3_evolution.py   # Dispatcher, Agents (Correction, Profiling...)
    └── utils/              # 工具函数
        ├── llm_client.py   # OpenAI API 封装 (支持 Structured Output)
        ├── math_utils.py   # 贝叶斯更新公式, 熵计算
        └── metrics.py      # NLL/Perplexity 计算器
```

---

## 5. 详细编码指南 (Detailed Coding Guide)

请按照以下逻辑模块进行编码实现。

### 5.1 数据结构定义 (`src/core/types.py`)

必须使用 `Pydantic` 定义，确保类型安全。

*   **`MemoryNode`**: `id`, `content`, `type` (Entity/Attribute/Hypothesis), `created_at`, `last_accessed`.
*   **`MemoryEdge`**: `source_id`, `target_id`, `relation`, `weight` (float 0.0-1.0), `timestamp`.
*   **`Intent`**: `label` (string), `confidence` (float).
*   **`SurprisalPacket`**: `content` (text), `score` (float), `retrieved_context` (list).

### 5.2 Layer 2: World Model (`src/layers/layer2_world_model.py`)

这是系统的基石，需要同时维护 **Graph** 和 **Vector Index**。

*   **Class `WeightedKnowledgeGraph`**:
    *   **Init**: 初始化 `NetworkX` DiGraph 和 `ChromaDB` collection。
    *   **Method `add_node(node)`**: 同时写入 Graph 和 Vector DB。
    *   **Method `add_edge(source, target, relation, weight)`**: 写入 Graph 边属性。
    *   **Method `soft_update_edge(source, target, relation, new_weight)`**:
        *   实现公式：$w_{new} = w_{old} \cdot \alpha$ (衰减) 或 $w_{new} = \min(1.0, w_{old} + \beta)$ (增强)。
    *   **Method `retrieve(query, intent_mask)`**:
        1.  使用 Embedding 检索 ChromaDB 获取 Top-K 节点。
        2.  **Intent Masking**: 过滤掉不属于当前 Intent 领域的节点（需要在 Node metadata 中预存 domain）。
        3.  **Graph Expansion**: 获取这些节点的 1-hop 邻居，优先选择 Edge Weight 高的路径。
        4.  返回结构化文本 Context。

### 5.3 Layer 1: Perception (`src/layers/layer1_perception.py`)

*   **Class `SlidingContextQueue`**:
    *   使用 `collections.deque`。
    *   实现 `add(user_input, system_response)`。
    *   当 `len > max_tokens` 时，执行 `popleft()` 并返回溢出的数据。

*   **Class `IntentRouter`**:
    *   使用 LLM (`gpt-4o-mini`) 进行分类。
    *   **Prompt:** "Analyze the user query. Classify intent into: [Coding, Academic, Personal, Casual]. Return JSON."

*   **Class `SurpriseMonitor`**:
    *   加载本地 Hugging Face 模型 (`gpt2` 或 `TinyLlama`)。
    *   **Method `calculate_surprisal(user_input, retrieved_context)`**:
        1.  Construct Prompt: `Context: {retrieved_context}\nUser: {user_input}`
        2.  计算 `user_input` 部分的 **Negative Log-Likelihood (NLL)**。
        3.  **Noise Handling:** 计算 Context 的熵 $H(C)$。如果 Context 极其稀疏或不相关，降低 NLL 的权重（实现 $S_{eff}$ 公式）。

### 5.4 Layer 3: Evolution (`src/layers/layer3_evolution.py`)

*   **Class `CognitiveEngine`**:
    *   **Method `process_packet(packet: SurprisalPacket)`**:
        *   根据 `packet.score` 对比阈值 `THETA_LOW`, `THETA_HIGH`。
        *   **Case High (> High):** 调用 `_correction_agent`。
        *   **Case Medium (> Low & <= High):** 调用 `_profiling_agent`。
        *   **Case Low (<= Low):** 调用 `_maintenance_agent`。

*   **Agents Implementation (LLM Prompts)**:
    *   **`_profiling_agent`**:
        *   Prompt: "User input is novel but not conflicting. Generate a **Hypothesis** about user's latent goal. Return JSON: {hypothesis_content, initial_confidence}."
        *   Action: 调用 L2 的 `add_node(type='Hypothesis')`。
    *   **`_correction_agent`**:
        *   Prompt: "Detect conflict between Input and Memory. Identify which memory is outdated."
        *   Action: 调用 L2 的 `soft_update_edge` (降低旧权重，添加新边)。

### 5.5 工具类 (`src/utils/`)

*   **`llm_client.py`**: 封装 OpenAI Client，实现重试机制。
*   **`math_utils.py`**:
    *   实现贝叶斯更新公式。
    *   实现 Sigmoid 函数用于初始化权重。

---

## 6. 编码提示 (Prompts for Coding Agent)

在生成代码时，请特别注意以下几点：

1.  **Mocking vs Real:** 对于 LLM 调用，请编写真实的代码，但允许通过 Config 切换到 Mock 模式以节省 Token。
2.  **Graph Persistence:** 使用 `networkx.read_gml` / `write_gml` 来保存图结构，不要只存在内存里。
3.  **Error Handling:** 向量数据库检索为空时，不要报错，应返回空 Context 并让 Surprise Monitor 处理（此时 Surprise 应被抑制）。
4.  **Asynchronous:** 虽然 Python 的 `asyncio` 很好，但为了科研代码的可读性，Layer 3 的处理可以先写成同步函数，在 `orchestrator` 中按顺序调用即可。
