# PCM 记忆系统处理流程详解

> 基于代码分析的完整记忆处理机制说明

---

## 目录

1. [系统概述](#1-系统概述)
2. [三层架构详解](#2-三层架构详解)
3. [完整处理流程](#3-完整处理流程)
4. [对话处理示例](#4-对话处理示例)
5. [核心数学公式](#5-核心数学公式)
6. [关键配置参数](#6-关键配置参数)

---

## 1. 系统概述

PCM (Proactive Cognitive Memory) 是一个**主动式认知记忆系统**，与传统被动存取的记忆系统不同，它能够：

| 能力 | 传统记忆系统 | PCM 系统 |
|------|------------|---------|
| 信息存储 | 被动存取 | 主动演化 |
| 冲突处理 | 无 | 自动检测并衰减 |
| 假设推理 | 无 | 生成并隐式验证 |
| 知识置信度 | 固定 | 贝叶斯动态更新 |

### 核心创新：惊奇度驱动

```
传统方法: 用户输入 → 检索 → 存储 (被动)
PCM方法:  用户输入 → 惊奇度评估 → 分级响应 → 自主演化 (主动)
```

---

## 2. 三层架构详解

```
┌─────────────────────────────────────────────────────────────┐
│                    PCM 三层架构                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │           Layer 1: 感知与工作记忆层                  │   │
│  │  • 滑动上下文队列 (工作记忆)                        │   │
│  │  • 意图路由器 (分类)                               │   │
│  │  • 惊奇度监测器 (计算)                             │   │
│  └─────────────────────────────────────────────────────┘   │
│                            ↓                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │           Layer 2: 概率世界模型层                    │   │
│  │  • 加权知识图谱 (NetworkX)                         │   │
│  │  • 向量存储 (JSON Vector Store)                    │   │
│  │  • 意图掩码检索                                    │   │
│  └─────────────────────────────────────────────────────┘   │
│                            ↓                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │           Layer 3: 认知演化引擎                      │   │
│  │  • 校正代理 (高惊奇) → 衰减冲突，创建新事实         │   │
│  │  • 画像代理 (中惊奇) → 生成假设                    │   │
│  │  • 维护代理 (低惊奇) → 强化知识                    │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 2.1 Layer 1: 感知与工作记忆层

**文件**: `src/layers/layer1_perception.py`

#### 滑动上下文队列 (SlidingContextQueue)

工作记忆，维护固定 token 窗口的对话历史。

```python
class SlidingContextQueue:
    """
    数据结构: Q_t = [u_{t-k}, r_{t-k}, ..., u_t]

    当 total_tokens > max_tokens 时触发驱逐:
    - 驱逐最旧的对话轮次
    - 返回 EvictedData 供 L3 处理
    """

    def add(self, role: str, content: str) -> Optional[EvictedData]:
        # 估算 token: token_count = len(content) // 4 + 1
        # 超限时驱逐旧内容
```

#### 意图路由器 (IntentRouter)

将用户查询分类到意图域。

```python
class IntentRouter:
    """
    两种模式:
    1. 固定域分类: [Coding, Academic, Personal, ...]
    2. 动态主题 (v1.2): LLM 提取任意主题
    """

    async def classify(self, query: str, context: str) -> Intent:
        # 返回: Intent(label, confidence, distribution)
```

#### 惊奇度监测器 (SurpriseMonitor)

计算新信息与已有知识的偏离程度。

```python
class SurpriseMonitor:
    """
    惊奇度公式:
    S_raw = α × semantic_distance + (1-α) × conflict_score
    S_eff = S_raw × (1 - λ × H(C_t))

    其中:
    - semantic_distance: 语义嵌入距离
    - conflict_score: LLM 冲突分析 [0, 1]
    - H(C_t): 检索熵 (检索质量指标)
    """
```

### 2.2 Layer 2: 概率世界模型层

**文件**: `src/layers/layer2_world_model.py`

#### 加权知识图谱

```python
class WeightedKnowledgeGraph:
    """
    组件:
    - NetworkX DiGraph: 存储节点关系
    - JSON Vector Store: 语义向量检索
    - SentenceTransformer: 生成嵌入向量
    """
```

#### 节点类型

```python
class NodeType(str, Enum):
    ENTITY = "entity"        # 实体 (e.g., "Python")
    ATTRIBUTE = "attribute"  # 属性 (e.g., "skill_level: expert")
    HYPOTHESIS = "hypothesis"  # 假设 (待验证)
    FACT = "fact"            # 事实 (已确认)
```

#### 检索公式

```python
# 意图掩码检索分数
Score(ε_k) = similarity × intent_relevance × weight

# 其中:
# - similarity: 查询与节点的余弦相似度
# - intent_relevance: 意图分布中该节点域的概率
# - weight: 节点置信权重 [0, 1]
```

### 2.3 Layer 3: 认知演化引擎

**文件**: `src/layers/layer3_evolution.py`

#### 三级代理路由

| 惊奇度级别 | 条件 | 触发代理 | 操作 |
|-----------|------|---------|------|
| **高** | S_eff > θ_high | CorrectionAgent | 衰减冲突节点，创建新事实 |
| **中** | θ_low < S_eff ≤ θ_high | ProfilingAgent | 生成假设节点 |
| **低** | S_eff ≤ θ_low | MaintenanceAgent | 强化现有知识 |

---

## 3. 完整处理流程

当用户输入一条消息时，系统按以下 7 步处理：

```
┌─────────────────────────────────────────────────────────────┐
│ 步骤 1: L2 初始检索                                         │
│   world_model.retrieve(user_input, intent=None)             │
│   → 获取初始相关节点 (无意图过滤)                           │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│ 步骤 2: L1 感知处理                                         │
│   a) 添加到工作记忆 → 可能触发驱逐                          │
│   b) 意图分类 → Intent(label, confidence, distribution)     │
│   c) 惊奇度计算 → SurprisalPacket(raw, effective, entropy)  │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│ 步骤 3: L2 意图掩码重检索                                   │
│   world_model.retrieve_with_expansion(query, intent=intent) │
│   → 使用意图信息优化检索结果                               │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│ 步骤 4: L3 认知演化                                         │
│   根据 S_eff 路由到对应代理:                                │
│   • 高惊奇 → CorrectionAgent (衰减+创建)                   │
│   • 中惊奇 → ProfilingAgent (生成假设)                     │
│   • 低惊奇 → MaintenanceAgent (强化)                       │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│ 步骤 5: 处理驱逐数据                                        │
│   将被驱逐的对话转为 FACT 节点存入 L2                       │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│ 步骤 6: 生成响应 (可选)                                     │
│   使用检索到的记忆上下文生成个性化回复                      │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│ 步骤 7: 保存状态                                            │
│   持久化知识图谱和中间结果                                  │
└─────────────────────────────────────────────────────────────┘
```

---

## 4. 对话处理示例

### 场景：用户兴趣转变

假设系统已有以下知识：
```
节点 A: "用户是 Python 后端开发者" (weight=0.85, type=FACT)
节点 B: "用户使用 FastAPI 框架" (weight=0.7, type=FACT)
```

### 示例对话 1: 低惊奇 (强化)

**用户输入**: "我今天用 FastAPI 写了一个 REST API"

```
处理流程:
├─ 步骤 1: 初始检索
│   └─ 找到节点 B (similarity=0.85)
│
├─ 步骤 2: L1 处理
│   ├─ 工作记忆: 添加消息
│   ├─ 意图分类: "Coding" (confidence=0.92)
│   └─ 惊奇度计算:
│       ├─ semantic_distance = 0.15 (很相似)
│       ├─ conflict_score = 0.1 (consistent)
│       ├─ raw_score = 0.6×0.15 + 0.4×0.1 = 0.13
│       ├─ retrieval_entropy = 0.1 (检索确定)
│       └─ effective_score = 0.13 × (1 - 0.3×0.1) = 0.126
│
├─ 步骤 3: 意图掩码重检索
│   └─ 节点 B 分数提升 (Coding 域匹配)
│
├─ 步骤 4: L3 演化 (effective_score=0.126 < θ_low=0.3)
│   └─ 路由到 MaintenanceAgent
│       ├─ 强化节点 B: w = 0.7 + 0.05×(1-0.7) = 0.715
│       └─ 创建引用节点 (保存原文)
│
└─ 结果:
    └─ 节点 B 权重: 0.7 → 0.715 (信念增强)
```

### 示例对话 2: 中惊奇 (假设生成)

**用户输入**: "我最近在学习 Transformer 和注意力机制"

```
处理流程:
├─ 步骤 1: 初始检索
│   └─ 找到节点 A (similarity=0.4, Python 开发相关)
│
├─ 步骤 2: L1 处理
│   ├─ 工作记忆: 添加消息
│   ├─ 意图分类: "Academic" (confidence=0.75)
│   └─ 惊奇度计算:
│       ├─ semantic_distance = 0.6 (新领域)
│       ├─ conflict_score = 0.4 (novel, 非矛盾)
│       ├─ raw_score = 0.6×0.6 + 0.4×0.4 = 0.52
│       ├─ retrieval_entropy = 0.3
│       └─ effective_score = 0.52 × (1 - 0.3×0.3) = 0.47
│
├─ 步骤 4: L3 演化 (0.3 < 0.47 ≤ 0.7)
│   └─ 路由到 ProfilingAgent
│       ├─ LLM 内部推理:
│       │   "用户是 Python 开发者，现在学习 Transformer..."
│       │   "可能正在转向 AI/ML 领域..."
│       │
│       └─ 生成假设节点:
│           ├─ content: "用户可能正在转型做 AI 研究"
│           ├─ type: HYPOTHESIS
│           ├─ weight: σ(0.47) mapped to [0.3,0.5] = 0.38
│           └─ evidence_keywords: ["AI", "ML", "Transformer"]
│
└─ 结果:
    ├─ 新增假设节点 (待未来验证)
    └─ 与节点 A 建立 "derived_from" 边
```

### 示例对话 3: 高惊奇 (信念校正)

**用户输入**: "我决定放弃编程，全职转做 AI 研究员"

```
处理流程:
├─ 步骤 1: 初始检索
│   └─ 找到节点 A, B (Python 后端开发相关)
│
├─ 步骤 2: L1 处理
│   ├─ 工作记忆: 添加消息
│   ├─ 意图分类: "Professional" (confidence=0.8)
│   └─ 惊奇度计算:
│       ├─ semantic_distance = 0.7
│       ├─ conflict_score = 0.85 (contradictory)
│       ├─ raw_score = 0.6×0.7 + 0.4×0.85 = 0.76
│       ├─ retrieval_entropy = 0.15
│       └─ effective_score = 0.76 × (1 - 0.3×0.15) = 0.73
│
├─ 步骤 4: L3 演化 (effective_score=0.73 > θ_high=0.7)
│   └─ 路由到 CorrectionAgent
│       ├─ LLM 诊断:
│       │   "用户兴趣发生重大转变"
│       │   "后端开发相关记忆已过时"
│       │
│       ├─ 衰减过时节点:
│       │   ├─ 节点 A: w = 0.85 × e^{-0.3×0.73} = 0.68
│       │   └─ 节点 B: w = 0.715 × e^{-0.3×0.73} = 0.57
│       │
│       └─ 创建新事实节点:
│           ├─ content: "用户全职从事 AI 研究"
│           ├─ type: FACT
│           ├─ weight: 0.8 (高初始权重)
│           └─ edges: "supersedes" → 节点 A
│
└─ 结果:
    ├─ 节点 A: 0.85 → 0.68 (衰减)
    ├─ 节点 B: 0.715 → 0.57 (衰减)
    ├─ 新增 FACT 节点 (AI 研究员)
    └─ 之前的假设可能被晋升为 FACT
```

### 示例对话 4: 假设验证与晋升

**后续用户输入**: "我的 AI 论文被顶会接收了！"

```
处理流程:
├─ 步骤 2: L1 处理
│   └─ effective_score = 0.25 (低惊奇，符合假设)
│
├─ 步骤 4: L3 演化 (低惊奇)
│   └─ 路由到 MaintenanceAgent
│       ├─ 强化 "AI 研究员" 节点: w = 0.8 → 0.81
│       ├─ 强化之前的假设节点: w = 0.38 → 0.41
│       └─ 检查假设晋升:
│           └─ 如果 w > 0.7 → 晋升为 FACT
│
└─ 结果:
    └─ 假设逐步被验证，权重增加
```

---

## 5. 核心数学公式

### 5.1 惊奇度计算

```
原始惊奇度:
S_raw = α × semantic_distance + (1-α) × conflict_score

检索熵 (衡量检索质量):
H(C_t) = -Σ ŝ(ε) × log(ŝ(ε))

有效惊奇度 (区分冲突和无知):
S_eff = S_raw × (1 - λ × H(C_t))

含义:
- 高熵 (检索不确定) → 折扣惊奇度 (可能是"无知"而非"冲突")
- 低熵 (检索确定) → 保留惊奇度 (可能是真正的"冲突")
```

### 5.2 权重更新公式

```
强化更新 (MaintenanceAgent, 低惊奇):
w_{t+1} = w_t + η × (1 - w_t)
         ↑ 渐近趋向 1.0，永不超过

衰减更新 (CorrectionAgent, 高惊奇):
w_{t+1} = w_t × e^{-β × S_eff}
         ↑ 指数衰减，惊奇度越高衰减越快

假设初始化 (ProfilingAgent, 中惊奇):
w_init = sigmoid(S_eff) mapped to [w_min, w_max]
       ↑ 映射到 [0.3, 0.5] 的保守权重
```

### 5.3 检索分数计算

```
意图掩码检索:
Score(ε_k) = sim(emb(u_t), emb(ε_k)) × P(d(ε_k)|I_t) × w_k
              ↑ 语义相似度        ↑ 意图相关性      ↑ 置信权重

混合检索 (可选):
Score = α×semantic + β×keyword + γ×graph + δ×recency
```

---

## 6. 关键配置参数

| 参数 | 默认值 | 说明 |
|------|--------|------|
| **Layer 1** | | |
| `MAX_CONTEXT_TOKENS` | 2000 | 工作记忆最大 token |
| `EVICTION_SIZE` | 2 | 驱逐轮次数 |
| **Layer 2** | | |
| `RETRIEVAL_TOP_K` | 10 | 检索结果数量 |
| `RETRIEVAL_MIN_SCORE` | 0.1 | 最小检索权重 |
| **Layer 3** | | |
| `THETA_LOW` | 0.3 | 低/中惊奇边界 |
| `THETA_HIGH` | 0.7 | 中/高惊奇边界 |
| `ETA` | 0.05 | 强化学习率 |
| `BETA` | 0.3 | 衰减因子 |
| **惊奇度** | | |
| `SURPRISAL_ALPHA` | 0.6 | 语义 vs LLM 权重 |
| `SURPRISAL_LAMBDA` | 0.3 | 熵调整因子 |

---

## 总结

PCM 记忆系统的核心特点：

1. **主动演化**: 不是被动存取，而是根据惊奇度主动更新知识
2. **三级响应**: 高/中/低惊奇度触发不同的认知代理
3. **软更新策略**: 永不删除节点，只调整权重（保留历史）
4. **隐式验证**: 假设通过未来观察自动验证，无需显式询问
5. **意图感知**: 检索时考虑意图相关性，提升精准度

```
用户输入 → 惊奇度评估 → 分级处理 → 知识演化 → 响应生成
            ↑                                    ↓
            └──────── 反馈闭环 ←─────────────────┘
```
