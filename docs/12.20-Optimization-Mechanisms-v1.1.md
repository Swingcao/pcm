# ProCoMemory Optimization Mechanisms v1.1

**Date:** 2024-12-20
**Version:** 1.1
**Status:** Implementation Complete

---

## Table of Contents

1. [Overview](#1-overview)
2. [Problem Statement](#2-problem-statement)
3. [New Module Architecture](#3-new-module-architecture)
4. [Module 1: Structured Fact Extractor](#4-module-1-structured-fact-extractor)
5. [Module 2: Keyword Index with BM25](#5-module-2-keyword-index-with-bm25)
6. [Module 3: Knowledge Graph Edge Creator](#6-module-3-knowledge-graph-edge-creator)
7. [Module 4: Hybrid Retriever](#7-module-4-hybrid-retriever)
8. [Integration Guide](#8-integration-guide)
9. [Configuration Reference](#9-configuration-reference)
10. [Expected Performance Improvements](#10-expected-performance-improvements)

---

## 1. Overview

This document describes four new optimization modules added to ProCoMemory to address poor performance on simple retrieval tasks (Single-hop, Multi-hop, Open-domain). These modules are designed to be:

- **Independent**: Each module can function standalone
- **Decoupled**: Minimal dependencies between modules
- **Backward Compatible**: Existing code continues to work

### New Files Created

```
ProCoMemory/src/utils/
├── fact_extractor.py      # Structured fact extraction from dialogue
├── keyword_index.py       # BM25 inverted index for keyword search
├── edge_creator.py        # Knowledge graph edge creation
└── hybrid_retriever.py    # Combined semantic + keyword retrieval
```

---

## 2. Problem Statement

### 2.1 Current Performance Issues

| Task Type | F1 Score | Error Rate | Root Cause |
|-----------|----------|------------|------------|
| Single-hop | 0.138 | 78.1% | Embedding similarity misses exact keywords |
| Multi-hop | 0.254 | 69.2% | No graph edges for multi-hop traversal |
| Temporal | 0.393 | 51.4% | Better (surprisal helps) |
| Adversarial | 0.292 | 64.3% | Moderate |

### 2.2 Root Causes Identified

1. **No Structured Facts**: Raw dialogue stored without extracting atomic facts
2. **Embedding-Only Retrieval**: Rare keywords (e.g., "Sweden", "violin") missed
3. **Zero Graph Edges**: 582 nodes, 0 edges - graph structure unused
4. **No Keyword Matching**: Missing TF-IDF/BM25 for lexical retrieval

### 2.3 Example Failure

```
Question: "What instruments does Melanie play?"
Expected: "clarinet and violin"
Actual: "The memory context does not provide information..."

Why: The word "violin" appears once in 582 nodes. Semantic similarity
     ranked other messages about "music" and "instruments" higher,
     missing the specific message containing the answer.
```

---

## 3. New Module Architecture

```
                    ┌─────────────────────────────────────────┐
                    │           User Query                    │
                    └─────────────────┬───────────────────────┘
                                      │
                    ┌─────────────────▼───────────────────────┐
                    │         HybridRetriever                 │
                    │  Score = α×semantic + β×keyword +       │
                    │          γ×graph + δ×recency            │
                    └─────┬───────────┬───────────┬───────────┘
                          │           │           │
         ┌────────────────▼──┐  ┌─────▼─────┐  ┌──▼────────────────┐
         │  Embedding Index  │  │  Keyword  │  │   Graph Edges     │
         │  (Existing L2)    │  │   Index   │  │   (EdgeCreator)   │
         │                   │  │  (BM25)   │  │                   │
         └────────────────────┘  └───────────┘  └───────────────────┘
                    ▲                 ▲                  ▲
                    │                 │                  │
         ┌──────────┴─────────────────┴──────────────────┴──────────┐
         │                    MemoryNodes                           │
         │            + StructuredFacts (NEW)                       │
         └──────────────────────────────────────────────────────────┘
                                      ▲
                                      │
                    ┌─────────────────┴───────────────────────┐
                    │           FactExtractor                 │
                    │    Raw Dialogue → Structured Facts      │
                    └─────────────────────────────────────────┘
```

---

## 4. Module 1: Structured Fact Extractor

**File:** `src/utils/fact_extractor.py`

### 4.1 Purpose

Transforms raw dialogue messages into structured, queryable facts in subject-predicate-object form.

### 4.2 Data Structure

```python
@dataclass
class StructuredFact:
    subject: str           # Entity (e.g., "Melanie")
    predicate: str         # Relation (e.g., "plays")
    object: str            # Object (e.g., "violin")
    temporal: Optional[str]  # Resolved time (e.g., "2022")
    location: Optional[str]  # Location if mentioned
    raw_message: str       # Original message for context
    source_timestamp: str  # When message was received
    confidence: float      # Extraction confidence (0.0-1.0)
    fact_type: str         # "attribute", "preference", "event", "general"
    keywords: List[str]    # Important keywords for indexing
```

### 4.3 Extraction Process

```
Input: "[1:56 pm on 8 May, 2023] Melanie: Yeah, I painted that lake sunrise last year!"

                    ┌─────────────────────────────┐
                    │     FactExtractor           │
                    │                             │
                    │  1. Parse timestamp         │
                    │  2. Extract speaker         │
                    │  3. LLM/Rule extraction     │
                    │  4. Temporal resolution     │
                    │  5. Keyword extraction      │
                    └─────────────┬───────────────┘
                                  │
                                  ▼
Output: StructuredFact(
    subject="Melanie",
    predicate="painted",
    object="lake sunrise",
    temporal="2022",          # "last year" resolved from May 2023
    fact_type="event",
    keywords=["melanie", "painted", "lake", "sunrise", "2022"]
)
```

### 4.4 Temporal Resolution

The `TemporalResolver` class converts relative temporal expressions to absolute dates:

| Expression | Reference Date | Resolved |
|------------|---------------|----------|
| "yesterday" | May 8, 2023 | May 7, 2023 |
| "last year" | May 8, 2023 | 2022 |
| "3 days ago" | May 8, 2023 | May 5, 2023 |
| "next month" | May 8, 2023 | June 2023 |

### 4.5 Usage

```python
from src.utils import FactExtractor, extract_facts_sync

# Async usage
extractor = FactExtractor(use_llm=True)
facts = await extractor.extract(
    message="[1:56 pm on 8 May, 2023] Caroline: I moved from Sweden 4 years ago.",
    timestamp="8 May, 2023"
)

# Sync wrapper
facts = extract_facts_sync(message, timestamp, use_llm=True)

# Result:
# StructuredFact(
#     subject="Caroline",
#     predicate="moved_from",
#     object="Sweden",
#     temporal="2019",
#     keywords=["caroline", "moved", "sweden", "2019"]
# )
```

---

## 5. Module 2: Keyword Index with BM25

**File:** `src/utils/keyword_index.py`

### 5.1 Purpose

Provides fast lexical matching using an inverted index with BM25 ranking, complementing semantic search.

### 5.2 Architecture

```
                    ┌─────────────────────────────────────┐
                    │          InvertedIndex              │
                    │                                     │
                    │  index: Dict[term, List[(doc_id,   │
                    │                          freq)]]    │
                    │                                     │
                    │  doc_freq: Dict[term, count]        │
                    │                                     │
                    │  documents: Dict[doc_id, Document]  │
                    └─────────────────────────────────────┘

Example Index:
┌─────────────┬──────────────────────────────────┐
│ Term        │ Postings [(doc_id, freq)]        │
├─────────────┼──────────────────────────────────┤
│ "melanie"   │ [(node_1, 2), (node_5, 1), ...]  │
│ "violin"    │ [(node_23, 1)]                   │
│ "sweden"    │ [(node_42, 1)]                   │
│ "lgbtq"     │ [(node_3, 1), (node_7, 2), ...]  │
└─────────────┴──────────────────────────────────┘
```

### 5.3 BM25 Scoring Formula

```
BM25(D, Q) = Σ IDF(qi) × (f(qi, D) × (k1 + 1)) / (f(qi, D) + k1 × (1 - b + b × |D|/avgdl))

Where:
- IDF(qi) = log((N - n(qi) + 0.5) / (n(qi) + 0.5) + 1)
- f(qi, D) = frequency of term qi in document D
- |D| = document length
- avgdl = average document length
- k1 = 1.2 (term frequency saturation)
- b = 0.75 (length normalization)
```

### 5.4 Why BM25 Helps

| Query | Semantic Search | BM25 Search |
|-------|----------------|-------------|
| "What instruments does Melanie play?" | Returns messages about music, instruments (general) | Matches "Melanie" + "play" → finds exact message |
| "Where did Caroline move from?" | Returns messages about moving, travel | Matches "Caroline" + "move" + "from" → finds Sweden |

### 5.5 Usage

```python
from src.utils import InvertedIndex, create_index_from_nodes

# Build index from nodes
index = create_index_from_nodes(memory_nodes)

# Or build manually
index = InvertedIndex()
index.add_document("node_1", "Melanie plays violin and clarinet")
index.add_document("node_2", "Caroline moved from Sweden 4 years ago")

# Search
results = index.bm25_search("What instruments does Melanie play?", top_k=10)

# Results: [SearchResult(doc_id="node_1", score=3.45, matched_terms=["melanie", "plays"])]

# TF-IDF alternative
results = index.tfidf_search(query, top_k=10)

# Exact match (for entity lookup)
results = index.exact_match_search("Sweden", top_k=5)
```

### 5.6 Persistence

```python
# Save index
index.save("/path/to/keyword_index.json")

# Load index
index = InvertedIndex()
index.load("/path/to/keyword_index.json")
```

---

## 6. Module 3: Knowledge Graph Edge Creator

**File:** `src/utils/edge_creator.py`

### 6.1 Purpose

Creates semantic edges between memory nodes to enable graph-based reasoning and multi-hop retrieval.

### 6.2 Edge Relation Types

```python
class EdgeRelationType:
    RELATED = "related"           # Same subject/entity
    SUPERSEDES = "supersedes"     # New fact replaces old (contradiction)
    FOLLOWS = "follows"           # Temporal sequence
    DERIVED_FROM = "derived_from" # Hypothesis from observation
    SIMILAR_TO = "similar_to"     # High semantic similarity
    SUPPORTS = "supports"         # Evidence supporting fact
    CONTRADICTS = "contradicts"   # Direct contradiction
    ELABORATES = "elaborates"     # Adds detail
```

### 6.3 Edge Creation Rules

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        Edge Creation Rules                              │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  Rule 1: Same Speaker                                                   │
│  ─────────────────────                                                  │
│  IF speaker(node_A) == speaker(node_B)                                  │
│  THEN create_edge(A → B, "related", weight=0.6)                         │
│                                                                         │
│  Rule 2: Shared Entities                                                │
│  ───────────────────────                                                │
│  IF entities(node_A) ∩ entities(node_B) ≠ ∅                            │
│  THEN create_edge(A → B, "related", weight=0.5 + 0.1×|shared|)         │
│                                                                         │
│  Rule 3: Contradiction Detection                                        │
│  ───────────────────────────────                                        │
│  IF LLM.detect_contradiction(node_A, node_B) = True                     │
│  THEN create_edge(A → B, "supersedes", weight=0.9)                      │
│       decay_weight(node_B, factor=0.5)                                  │
│                                                                         │
│  Rule 4: Temporal Sequence                                              │
│  ─────────────────────────                                              │
│  IF speaker(A) == speaker(B) AND timestamp(A) > timestamp(B)            │
│  THEN create_edge(A → B, "follows", weight=0.8 - 0.01×days_diff)        │
│                                                                         │
│  Rule 5: Semantic Similarity                                            │
│  ───────────────────────────                                            │
│  IF cosine_similarity(emb_A, emb_B) >= 0.8                              │
│  THEN create_edge(A → B, "similar_to", weight=similarity)               │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### 6.4 Entity Extraction

```python
class EntityExtractor:
    @classmethod
    def extract_speaker(cls, content: str) -> Optional[str]:
        """Extract speaker from '[timestamp] Speaker: message' format."""

    @classmethod
    def extract_entities(cls, content: str) -> Set[str]:
        """Extract named entities (people, places, etc.)"""
```

### 6.5 Contradiction Detection

Two modes available:

**LLM-Based (Accurate):**
```python
prompt = """Analyze if these two statements contain contradictory information.

Statement 1 (newer): {new_node.content}
Statement 2 (older): {existing_node.content}

Output JSON:
{
    "is_contradictory": true/false,
    "contradiction_type": "none|direct|temporal|partial",
    "confidence": 0.0-1.0,
    "explanation": "..."
}"""
```

**Rule-Based (Fast):**
```python
# Pattern matching for opposite sentiments
patterns = [
    (r"like|love|enjoy", r"dislike|hate|don't like"),
    (r"live in (\w+)", r"moved from|used to live"),
    (r"am|is (\w+)", r"was|used to be"),
]
```

### 6.6 Usage

```python
from src.utils import EdgeCreator, create_edges_for_graph

# Async: Create edges for entire graph
edges = await create_edges_for_graph(
    nodes=memory_nodes,
    embeddings=embeddings_dict,  # Optional for similarity edges
    use_llm=True,                # Use LLM for contradiction detection
    max_edges_per_node=5
)

# Sync wrapper
edges = create_edges_sync(nodes, embeddings, use_llm=False)

# Create edges for a single new node
creator = EdgeCreator(use_llm=True)
edges = await creator.create_edges_for_node(
    new_node=new_memory_node,
    existing_nodes=all_other_nodes,
    embeddings=embeddings_dict
)
```

### 6.7 Before vs After

```
BEFORE (0 edges):
┌─────────┐   ┌─────────┐   ┌─────────┐
│ Node 1  │   │ Node 2  │   │ Node 3  │
│Melanie: │   │Melanie: │   │Caroline:│
│ violin  │   │ clarinet│   │ Sweden  │
└─────────┘   └─────────┘   └─────────┘

AFTER (with edges):
┌─────────┐ ──related──▶ ┌─────────┐
│ Node 1  │              │ Node 2  │
│Melanie: │ ◀─related─── │Melanie: │
│ violin  │              │ clarinet│
└─────────┘              └─────────┘
     │                        │
     └──────similar_to────────┘
```

---

## 7. Module 4: Hybrid Retriever

**File:** `src/utils/hybrid_retriever.py`

### 7.1 Purpose

Combines multiple retrieval signals (semantic, keyword, graph, recency) for robust retrieval.

### 7.2 Retrieval Formula

```
Score(d) = α × semantic_similarity +
           β × bm25_keyword_score +
           γ × graph_expansion_score +
           δ × recency_bonus

Default weights: α=0.4, β=0.3, γ=0.2, δ=0.1
```

### 7.3 Architecture

```
                          Query: "What instruments does Melanie play?"
                                            │
                    ┌───────────────────────┼───────────────────────┐
                    │                       │                       │
                    ▼                       ▼                       ▼
           ┌────────────────┐    ┌─────────────────┐    ┌─────────────────┐
           │   Semantic     │    │    Keyword      │    │     Graph       │
           │   Search       │    │    Search       │    │   Expansion     │
           │                │    │                 │    │                 │
           │ Query Emb vs   │    │ BM25 on         │    │ 1-hop neighbors │
           │ Node Embs      │    │ "melanie plays" │    │ of seed nodes   │
           └───────┬────────┘    └────────┬────────┘    └────────┬────────┘
                   │                      │                      │
                   ▼                      ▼                      ▼
           ┌────────────────┐    ┌─────────────────┐    ┌─────────────────┐
           │ node_5: 0.82   │    │ node_23: 3.45   │    │ node_24: 0.65   │
           │ node_12: 0.78  │    │ node_5: 2.10    │    │ node_25: 0.42   │
           │ node_23: 0.71  │    │ node_12: 1.85   │    │                 │
           └───────┬────────┘    └────────┬────────┘    └────────┬────────┘
                   │                      │                      │
                   └──────────────────────┼──────────────────────┘
                                          │
                                          ▼
                              ┌─────────────────────┐
                              │   Score Fusion      │
                              │                     │
                              │ 1. Normalize each   │
                              │ 2. Weight & combine │
                              │ 3. Re-rank          │
                              └──────────┬──────────┘
                                         │
                                         ▼
                              ┌─────────────────────┐
                              │   Final Results     │
                              │                     │
                              │ node_23: 0.89 ✓     │
                              │ node_5: 0.76        │
                              │ node_12: 0.71       │
                              └─────────────────────┘
```

### 7.4 Score Fusion Methods

**Linear Combination (Default):**
```python
combined[doc_id] = Σ weight[source] × normalized_score[source][doc_id]
```

**Reciprocal Rank Fusion (RRF):**
```python
RRF(d) = Σ 1 / (k + rank_i(d))   # k=60 typically
```

**Max Score Fusion:**
```python
combined[doc_id] = max(score[source][doc_id] for source in sources)
```

### 7.5 Configuration

```python
@dataclass
class RetrievalConfig:
    # Fusion weights (must sum to 1.0)
    semantic_weight: float = 0.4    # α
    keyword_weight: float = 0.3     # β
    graph_weight: float = 0.2       # γ
    recency_weight: float = 0.1     # δ

    # Retrieval parameters
    top_k: int = 10
    over_fetch_factor: int = 3      # Fetch 3x for re-ranking
    min_weight: float = 0.1         # Node weight threshold

    # Graph expansion
    expansion_depth: int = 1
    edge_discount: float = 0.5      # Neighbor score discount

    # BM25 parameters
    bm25_k1: float = 1.2
    bm25_b: float = 0.75
```

### 7.6 Usage

```python
from src.utils import HybridRetriever, RetrievalConfig, create_hybrid_retriever

# Method 1: Factory function
retriever = create_hybrid_retriever(
    nodes=memory_nodes,
    embeddings=embeddings_dict,
    edges=edge_list,
    config=RetrievalConfig(semantic_weight=0.4, keyword_weight=0.4)
)

# Method 2: Manual construction
config = RetrievalConfig(
    semantic_weight=0.3,
    keyword_weight=0.4,  # Increase for factual queries
    graph_weight=0.2,
    recency_weight=0.1
)
retriever = HybridRetriever(config=config)
retriever.build_from_nodes(nodes, embeddings, edges)

# Basic retrieval
results = retriever.retrieve(
    query="What instruments does Melanie play?",
    query_embedding=query_emb,
    top_k=10
)

# With graph expansion
results = retriever.retrieve_with_expansion(
    query="What instruments does Melanie play?",
    query_embedding=query_emb,
    expansion_depth=2
)

# Access result details
for result in results:
    print(f"Node: {result.node.id}")
    print(f"Final Score: {result.final_score:.3f}")
    print(f"Semantic: {result.semantic_score:.3f}")
    print(f"Keyword: {result.keyword_score:.3f}")
    print(f"Matched: {result.matched_keywords}")
```

### 7.7 Persistence

```python
# Save state
retriever.save("/path/to/retriever_state/")

# Load state
retriever = HybridRetriever()
retriever.load("/path/to/retriever_state/")
```

---

## 8. Integration Guide

### 8.1 Integration with Existing L2 (WeightedKnowledgeGraph)

```python
# In layer2_world_model.py

from src.utils import (
    HybridRetriever,
    RetrievalConfig,
    InvertedIndex,
    EdgeCreator,
    FactExtractor
)

class WeightedKnowledgeGraph:
    def __init__(self, ...):
        # Existing initialization
        self.graph = nx.DiGraph()
        self.vector_store = JSONVectorStore(...)

        # NEW: Add hybrid retriever
        self.hybrid_retriever = HybridRetriever(
            config=RetrievalConfig(
                semantic_weight=0.4,
                keyword_weight=0.3,
                graph_weight=0.2,
                recency_weight=0.1
            )
        )

        # NEW: Add fact extractor
        self.fact_extractor = FactExtractor(use_llm=True)

        # NEW: Add edge creator
        self.edge_creator = EdgeCreator(use_llm=False)  # Fast mode

    async def add_node(self, node: MemoryNode) -> str:
        # Existing: Add to graph and vector store
        self.graph.add_node(node.id, **node.to_graph_dict())
        embedding = self.embedding_model.encode(node.content).tolist()
        self.vector_store.upsert(...)

        # NEW: Add to hybrid retriever
        self.hybrid_retriever.add_node(node, embedding)

        # NEW: Create edges to existing nodes
        existing_nodes = [self.get_node(nid) for nid in self.graph.nodes()]
        edges = await self.edge_creator.create_edges_for_node(
            node, existing_nodes, self._get_embeddings()
        )
        for edge in edges:
            self.add_edge(edge.source_id, edge.target_id, edge.relation, edge.weight)
            self.hybrid_retriever.add_edge(edge.source_id, edge.target_id, edge.weight)

        return node.id

    def retrieve(self, query: str, intent: Intent = None, top_k: int = 10):
        # NEW: Use hybrid retrieval
        query_embedding = self.embedding_model.encode(query).tolist()

        results = self.hybrid_retriever.retrieve(
            query=query,
            query_embedding=query_embedding,
            intent=intent,
            top_k=top_k
        )

        nodes = [r.node for r in results]
        scores = [r.final_score for r in results]

        return nodes, scores
```

### 8.2 Integration with L1 (Perception Layer)

```python
# In layer1_perception.py

from src.utils import FactExtractor, extract_facts_sync

class PerceptionLayer:
    def __init__(self):
        self.fact_extractor = FactExtractor(use_llm=True)

    async def process_message(self, message: str, timestamp: str):
        # Extract structured facts
        facts = await self.fact_extractor.extract(message, timestamp)

        # Store both raw message AND structured facts
        raw_node = MemoryNode(content=message, node_type=NodeType.FACT)

        for fact in facts:
            fact_node = MemoryNode(
                content=fact.to_searchable_text(),
                node_type=NodeType.FACT,
                metadata={
                    "subject": fact.subject,
                    "predicate": fact.predicate,
                    "object": fact.object,
                    "temporal": fact.temporal,
                    "raw_message": fact.raw_message,
                    "keywords": fact.keywords
                }
            )
            # Add to world model
            await self.world_model.add_node(fact_node)

        return raw_node, facts
```

---

## 9. Configuration Reference

### 9.1 RetrievalConfig Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `semantic_weight` | float | 0.4 | Weight for embedding similarity |
| `keyword_weight` | float | 0.3 | Weight for BM25 score |
| `graph_weight` | float | 0.2 | Weight for graph expansion |
| `recency_weight` | float | 0.1 | Weight for recency bonus |
| `top_k` | int | 10 | Number of results to return |
| `over_fetch_factor` | int | 3 | Multiplier for initial fetch |
| `min_weight` | float | 0.1 | Minimum node weight threshold |
| `expansion_depth` | int | 1 | Graph expansion hops |
| `edge_discount` | float | 0.5 | Discount for neighbor scores |
| `bm25_k1` | float | 1.2 | BM25 term saturation |
| `bm25_b` | float | 0.75 | BM25 length normalization |

### 9.2 Recommended Configurations

**For Factual Queries (Single-hop, Multi-hop):**
```python
config = RetrievalConfig(
    semantic_weight=0.3,
    keyword_weight=0.5,  # High keyword weight
    graph_weight=0.15,
    recency_weight=0.05
)
```

**For Temporal Queries:**
```python
config = RetrievalConfig(
    semantic_weight=0.4,
    keyword_weight=0.3,
    graph_weight=0.2,
    recency_weight=0.1  # Higher recency
)
```

**For Multi-hop Reasoning:**
```python
config = RetrievalConfig(
    semantic_weight=0.3,
    keyword_weight=0.3,
    graph_weight=0.35,  # High graph weight
    recency_weight=0.05,
    expansion_depth=2   # 2-hop expansion
)
```

---

## 10. Expected Performance Improvements

### 10.1 Projected Metrics

| Metric | Current | Target | Improvement |
|--------|---------|--------|-------------|
| Single-hop F1 | 0.138 | 0.50+ | +262% |
| Multi-hop F1 | 0.254 | 0.45+ | +77% |
| Temporal F1 | 0.393 | 0.50+ | +27% |
| Retrieval Recall@10 | ~30% | 70%+ | +133% |
| Graph Edges | 0 | 1000+ | ∞ |

### 10.2 Why These Improvements

1. **Keyword Index (BM25)**: Rare terms like "Sweden", "violin" will be matched directly
2. **Structured Facts**: Atomic facts enable precise matching for specific queries
3. **Graph Edges**: Multi-hop queries can traverse relationships
4. **Hybrid Fusion**: Multiple signals reduce false negatives

### 10.3 Validation Checklist

- [ ] Run LoCoMo benchmark with new retriever
- [ ] Measure Retrieval Recall@10 improvement
- [ ] Verify edge count > 500 for test dataset
- [ ] Compare keyword vs semantic retrieval hit rates
- [ ] Test temporal resolution accuracy

---

## Appendix A: File Summary

| File | Lines | Key Classes/Functions |
|------|-------|----------------------|
| `fact_extractor.py` | ~350 | `StructuredFact`, `FactExtractor`, `TemporalResolver` |
| `keyword_index.py` | ~400 | `InvertedIndex`, `Tokenizer`, `SearchResult` |
| `edge_creator.py` | ~380 | `EdgeCreator`, `EdgeCandidate`, `EdgeRelationType` |
| `hybrid_retriever.py` | ~420 | `HybridRetriever`, `RetrievalConfig`, `ScoreFusion` |

---

## Appendix B: Dependencies

New external dependencies:
- `python-dateutil`: For relative date parsing in `TemporalResolver`

Install with:
```bash
pip install python-dateutil
```

All other dependencies are already in the project (numpy, pydantic, etc.).
